classdef DatabaseAnalysis < handle & DataSource & Cacheable

    properties(SetAccess=?Cacheable)
        % time which the analysis started running
        timeRun

        % has this analysis run already?
        hasRun = false;

        % is the analysis currently running? used by internal functions
        % to allow error-free calling of runOnEntry outside of .run()
        isRunning = false;

        % the result table will be an instance of DatabaseAnalysisResultsTable 
        resultTable

        % will be populated post analysis. All of this info is in .resultTable as well
%         successByEntry
%         exceptionByEntry
%         logByEntry

        % each element contains a struct with fields
        %   .pathNoExt
        %   .fileNameNoExt
        %   .extensions
        %   .name
        %   .caption
        %   .width
        %   .height
        %figureInfoByEntry = {};
        
        % there are two modes in which the results of this analysis can persist.
        % if cacheResultsIndividually is false, the results will be saved with
        % the table, ,,j
        %cacheResultsIndividually = false;
       
    end

    properties
        figureExtensions = {'fig', 'png', 'svg', 'pdf'};
        
        runDescription = ''; % added to the top of each report
    end
    
    properties(SetAccess=protected, Transient) 
        % used internally when calling methods on the analysis
        % from within runOnEntry (e.g. saveFigure)
        figureInfoCurrentEntry
        currentEntry
    end
    
    properties(Transient, SetAccess=protected)
        % reference to the current database when running
        database 
    end

    properties(Dependent)
        fieldsAnalysis
        
        pathAnalysisRoot
        pathAnalysis 
        pathCurrent
        pathFigures
        htmlFile
    end

    methods(Abstract) % METHODS EVERY ANALYSIS MUST IMPLEMENT
        % return a single word descriptor for this analysis, ignoring parameter
        % settings in param. The results will be stored as a DataTable with this
        % as the entryName
        name = getName(da);

        % return the entryName corresponding to the table in the database which this
        % analysis runs on. The DataTable with this entry name will run this analysis
        % once on each entry and map the results via a 1-1 relationship 
        entryName = getMapsEntryName(da);
    
        % return a list of fields generated by the analysis. These need to be declared
        % ahead of time to simplify many of the caching related features.
%         [fields, fieldDescriptorMap] = getFieldsAnalysis(da);
%         [fieldStructToFieldDescriptor] = getFieldsAnalysis(da);
        [varargout] = getFieldsAnalysis(da);

        % run this analysis on one entry, entryTable will be a DataTable instance
        % filtered down to one entry
        resultStruct = runOnEntry(da, entry, fields)
    end

    methods % not necessary to override if the defaults are okay
        % return the parameters that describe this particular instance of the analysis 
        % these will be used when caching. If these are changed, the old
        % analysis results will no longer be found
        function param = getCacheParam(da)
            param = struct();
        end

        
        % return a string used to describe the params used for t]his analysis
        % should encompass whatever is returned by getCacheParam()
        function str = getDescriptionParam(da)
            str = structToString(da.getCacheParam(), '; ');
        end
        
        % return fields here that you wish to have custom control over the
        % save load process
        function fields = getFieldsCustomSaveLoad(da, other)
            fields = {};
        end
        
        function data = loadValuesCustomForEntry(da, entry, fields, extraInfo)
            % here entry will be the mapped entry, not the 
            error('Please override loadValuesCustomForEntry if you wish to use getFieldsCustomSaveLoad');
        end
        
        function saveValuesCustomForEntry(da, entry, data, extraInfo)
            error('Please override saveValuesCustomForEntry if you wish to use getFieldsCustomSaveLoad');
        end
        
        % determine if this DatabaseAnalysis instance is equivalent to other,
        % an instance which has already been loaded in the Database.
        function tf = isequal(da, other)
            tf = true;
            if ~strcmp(class(da), class(other))
                tf = false;
                return;
            end
            if ~isequal(da.getCacheParam(), other.getCacheParam())
                tf = false;
                return;
            end
        end
        
        function tf = getCacheFieldsIndividually(da) %#ok<*MANU>
            tf = false;
        end

        function tf = getRerunCachedUnsuccessful(da)
            tf = false;
        end

        % returns a list of entryNames that this analysis references
        % this is used when retrieving analysis results from the cache. If a related
        % table has changed, the analysis will be rerun on all entries.
        function list = getReferencesRelatedEntryNames(da)
            list = {};
        end

        % An analysis runs on each entry of a specific data table, and may reference
        % related tables through relationships in the database. When any of these
        % data tables is modified, this could invalidate the results of an analysis
        % for some or all of the entries. However, for caching to be at all useful
        % we simply issue a warning when using cached analysis results that references
        % a datatable that has changed. We assume that all changes have been additive
        % and do not affect the analysis that has already been run. Thus we only 
        % run the analysis on entries that are missing related rows in this analysis.
        % 
        % However, if this will yield incorrect results, you can specify that
        % when certain tables are changed at all, the entire cached analysis 
        % becomes invalid. Return a list of the .entryName of these tables here.
        function list = getEntryNamesChangesInvalidateCache(da)
            list = {};
        end
        
        % return a cell array of DataSource instances that must be loaded a priori,
        % These sources will ALWAYS be run, even when all analysis can be loaded 
        % from cache. If a source is needed only when doing new analysis, e.g.
        % another analysis this builds upon, include it in getRequiredSourcesForAnalysis
        % instead.
        function sources = getRequiredSources(da)
            sources = {};
        end

        % return a cell array of DataSource instances that must be loaded ONLY
        % when new analysis is to actually be run (not just loading from cache)
        function sources = getRequiredSourcesForAnalysis(da)
            sources = {};
        end
        
        % return a cell array of DatabaseView instances that must be applied before 
        % running this analysis
        function views = getRequiredViews(da)
            views = {};
        end
        
        % filter the data table as necessary before this analysis is run
        % table.entryName will match the result of getMapsEntryName() above
        % 
        % If the filtering pattern is a common one, consider turning it into a 
        % DatabaseView class and returning an instance from getDatabaseViewsToApply()
        function [table, changed] = preFilterTable(da, table) %#ok<*INUSL>
            % default does nothing
            changed = false;
        end

        % return a list of additional meta fields that resultTable will contain
        % in addition to the analysis field and keyFields
        function [fields, fieldDescriptorMap] = getFieldsAdditional(da, table) %#ok<*INUSD>
            fieldDescriptorMap = ValueMap('KeyType', 'char', 'ValueType', 'any');
            fieldDescriptorMap('success') = BooleanField();
            fieldDescriptorMap('output') = OutputField();
            fieldDescriptorMap('runTimestamp') = DateTimeField();
            fieldDescriptorMap('exception') = UnspecifiedField();
            fieldDescriptorMap('figureInfo') = UnspecifiedField();
            fields = fieldDescriptorMap.keys;
        end
        
        % return the list of fields to load when the analysis is loaded
        % into the database as a DataSource via .loadSource()
        function fieldsToLoad = getFieldsToLoadOnDataSourceLoad(da)
            % by default load all displayable fields
            fieldsToLoad = {'success', 'runTimestamp', 'output', 'exception'};
                
            if ~isempty(da.resultTable)
                fieldsToLoad = union(fieldsToLoad, ...
                    intersect(da.resultTable.fieldsLoadOnDemand, da.resultTable.fieldsDisplayable));
            end
        end
            
    end

    methods % Constructor
        function da = DatabaseAnalysis(varargin)
            
        end 
    end

    methods
        function setDatabase(da, db)
            %assert(~da.hasRun, 'Database cannot be changed after analysis has run');
            assert(isempty(db) || isa(db, 'Database'), 'Must be a Database instance');
            da.database = db;
        end
        
        % originally i defined getFieldsAnalysis to use a value map, then I
        % decided to switch to a struct format. this provides easy
        % compatibility
        function [fields, map] = getFieldsAnalysisAsValueMap(da)
            try 
                [fields, map] = da.getFieldsAnalysis();
            catch
                fstruct = da.getFieldsAnalysis();
                fields = fieldnames(fstruct);
                map = ValueMap.fromStruct(fstruct);
            end
        end
        
        function checkHasRun(da)
            if ~da.hasRun
                error('Analysis has not yet been run. Please call .run() first.');
            end
        end
        
        function checkIsRunning(da)
            if ~da.getIsRunning()
                error('Analysis is not currently running. Please call .run() first.');
            end
        end
        
        function tf = getIsRunning(da)
            tf = da.isRunning || da.hasRun;
        end
        
        function readyDatabase(da)    
            % set up in database
            if isempty(da.database)
                error('Please call .setDatabase(db) first');
            end
            
            % load all data sources
            da.database.loadSource(da.getRequiredSources());
            
            % load all data views 
            da.database.applyView(da.getRequiredViews()); 
        end
        
        function initialize(da, varargin)
            p = inputParser;
            p.addParameter('maxRows', Inf, @isscalar);
            p.parse(varargin{:});
            
            name = da.getName();
            assert(isvarname(name), 'getName() must return a valid variable name');
            debug('Initializing DatabaseAnalysis %s\n', name);

            da.readyDatabase();
            
            currentResultTable = da.resultTable;
            
            % build the resultTable as a LoadOnDemandTable
            % this will be a skeleton containing all of the fields for the analysis
            % none of which will be loaded initially
            resultTable = DatabaseAnalysisResultsTable(da, 'maxRows', p.Results.maxRows);
                
            if ~isempty(currentResultTable)
                debug('Merging current results table into newly mapped results table, some entries may be dropped\n');
                resultTable = resultTable.mergeEntriesWith(currentResultTable, 'keyFieldMatchesOnly', true);
            end
            
            da.resultTable = resultTable.setDatabase(da.database).updateInDatabase('filterOneToRelationships', false);
            entryName = da.getMapsEntryName();
           
            % empty entry name means runs once on entire database
            if ~isempty(entryName)
                da.database.addRelationshipOneToOne(da.resultTable.entryName, entryName); 
            end
            
            da.database.markSourceLoaded(da);
        end
        
        function runDebug(da, varargin)
            % wraps .run with common params for debugging but won't
            % actually do any saving
            p = inputParser();
            p.addParameter('maxRows', 10, @isscalar);
            p.KeepUnmatched = true;
            p.parse(varargin{:});
            
            dbstop if error;
            da.run('keepCurrentValues', false, 'loadCache', false, ...
                'saveCache', false, 'catchErrors', false, 'rerunFailed', true, ...
                'maxToRun', p.Results.maxRows, p.Unmatched);
        end
        
        function runDebugErrors(da, varargin)
            % wraps .run with common params for debugging but will actually
            % do work if nothing goes wrong
            dbstop if error;
            da.run('keepCurrentValues', false, 'loadCache', true, ...
                'saveCache', true, 'catchErrors', false, 'rerunFailed', true);
        end
        
        function rerun(da, varargin)
            % wraps .run with common params for debugging, i.e. don't
            % saveCache, loadCache, catchErrors, but do rerunFailed
            da.run('keepCurrentValues', false, 'loadCache', false, ...
                'rerunFailed', true, varargin{:});
        end
        
        function rerunDebugErrors(da, varargin)
            % wraps .run with common params for debugging but will actually
            % do work if nothing goes wrong
            dbstop if error;
            da.run('keepCurrentValues', false, 'loadCache', false, ...
                'saveCache', true, 'catchErrors', false);
        end
        
        function rerunFailed(da, varargin)
            da.run('rerunFailed', true, varargin{:});
        end
        
        function rerunFailedDebugErrors(da, varargin)
            % wraps .run with common params for debugging but will actually
            % do work if nothing goes wrong
            dbstop if error;
            da.run('rerunFailed', true, 'saveCache', true, 'catchErrors', false);
        end
        
        function rerunFailedDebug(da, varargin)
            dbstop if error;
            da.run('rerunFailed', true, 'catchErrors', false, 'saveCache', false, varargin{:});
        end
        
        function runDebugOnIdx(da, idx, varargin);
            da.runDebug('idx', idx, varargin{:});
        end

        function run(da, varargin)
            p = inputParser();
            p.addParameter('desc', '', @ischar);
            p.addParameter('database', [], @(db) isempty(db) || isa(db, 'Database'));
            % optionally select subset of fields for analysis
            p.addParameter('fields', da.fieldsAnalysis, @iscellstr); 
            % check the cache for existing analysis values
            p.addParameter('loadCache', true, @islogical); 
            % load the cached success value so we know which entries have been run
            p.addParameter('loadCacheSuccessOnly', false, @islogical);
            % look at cached field value timestamps and invalidate them if they
            % are newer than the most recent modification to any table returned 
            % by getEntryNamesChangesInvalidateCache()
            p.addParameter('checkCacheTimestamps', true, @islogical);
            % save computed analysis values to the cache
            p.addParameter('saveCache', true, @islogical); 
            % rerun any failed entries from prior runs, true value supersedes
            % .getRerunFailed() method return value, which is the class default
            p.addParameter('rerunFailed', false, @islogical); 
            % don't run any new analysis, just load whatever possible from the cache
            p.addParameter('loadCacheOnly', false, @islogical);
            % wrap the runOnEntry method in a try/catch block so that errors
            % on one entry don't halt the analysis
            p.addParameter('catchErrors', true, @islogical);
            % generate a new report and figures folder even if no new analysis
            % was run, useful if issues encountered with report generation
            p.addParameter('forceReport', false, @islogical);
            % limit the indices that are run from the table
            p.addParameter('idx', [], @(x) isempty(x) || isvector(x));
            
            % will drop the current results table before loading new values
            % if true, otherwise will merge it in
            p.addParameter('keepCurrentValues', false, @islogical);
            
            % limit this for debugging to make things go faster initially
            p.addParameter('maxRows', Inf, @isscalar);
            
            % for debug purposes mainly, run only on this many entries
            p.addParamValue('maxToRun', Inf, @isscalar);
            
            % for new entries that run, they will be unloaded from the table immediately
            % if this is false so as to prevent memory overflows for large analyses
            % if true, new analysis results will be kept in the table, 
            % but old results will still need to be loaded using
            % loadFields. Note that if saveCache is false, storeInTable
            % will always be overridden to true so that the results are
            % accessible.
            p.addParameter('storeInTable', false, @islogical);
            
            p.addParameter('verbose', false, @islogical);
            p.parse(varargin{:});

            fieldsAnalysis = p.Results.fields;
            loadCache = p.Results.loadCache;
            loadCacheSuccessOnly = p.Results.loadCacheSuccessOnly;
            checkCacheTimestamps = p.Results.checkCacheTimestamps;
            saveCache = p.Results.saveCache;
            rerunFailed = p.Results.rerunFailed;
            loadCacheOnly = p.Results.loadCacheOnly;
            catchErrors = p.Results.catchErrors;
            forceReport = p.Results.forceReport;
            storeInTable = p.Results.storeInTable;
            keepCurrentValues = p.Results.keepCurrentValues;
            maxToRun = p.Results.maxToRun;
            db = p.Results.database;
            verbose = p.Results.verbose;
            
            if ~saveCache
                storeInTable = true;
            end
            
            % get analysis name
            name = da.getName();
            debug('Preparing for analysis : %s\n', name);
            
            if ~isempty(db)
                da.setDatabase(db);
            end
            db = da.database;            
            
            % call this before calling preFilterTable below!
            da.readyDatabase();
            
            % get the appropriate table to map
            entryName = da.getMapsEntryName();
            if isempty(entryName)
                table = StructTable(struct(), 'entryName', 'database');  
            else
                table = db.getTable(entryName);
                % enforce singular for 1:1 relationship to work
                entryName = table.entryName;
                
                % prefilter the table further if requested (database views also do this)
                debug('Filtering mapped table %s via preFilterTable\n', entryName);
                [table, changed] = da.preFilterTable(table);
                if changed
                    table = table.updateInDatabase();
                end
            end
            
            % load required source/views, re-map the result table, etc.
            if ~keepCurrentValues
                da.resultTable = [];
            end
            da.initialize('maxRows', p.Results.maxRows);
            resultTable = da.resultTable;
            
            da.isRunning = true;

            % mark run timestamp consistently for all entries
            % we'll keep this timestamp unless we don't end up doing any new
            % analysis, then we'll just pick the most recent prior timestamp
            da.timeRun = now;
            fieldsAdditional = da.getFieldsAdditional();
               
            [allFieldsAnalysis, allDFDAnalysis] = da.getFieldsAnalysisAsValueMap();
            for iField = 1:length(fieldsAnalysis)
                dfd = allDFDAnalysis(fieldsAnalysis{iField});
                fieldsAnalysisIsDisplayable(iField) = dfd.isDisplayable();
            end

            % keep track of whether we need to re-cache the result table 
            resultTableChanged = false;

            if maxToRun < resultTable.nEntries
                debug('Selecting only first %d entries to run on\n', maxToRun);
                resultTable = resultTable.select(1:maxToRun);
            end
            
            % mask by entry of which entries must be run
            maskAlreadyRun = false(resultTable.nEntries, 1);
            maskFailed = false(resultTable.nEntries, 1);
            maskToAnalyze = true(resultTable.nEntries, 1);
            maskCacheInvalidates = false(resultTable.nEntries, 1);
           
            tableListCacheWarning = makecol(da.getReferencesRelatedEntryNames());
            tableListCacheInvalidate = makecol(da.getEntryNamesChangesInvalidateCache());
            
            cacheFieldsIndividually = da.getCacheFieldsIndividually();
            
            if loadCacheSuccessOnly
                % only loading the success field, not running any new
                % entries, used primarly by DataSource.loadSource
                
                debug('Loading cached success field for all entries\n');
                % load success so that we can check failed entries later
                resultTable = resultTable.loadFields('fields', {'success'}, 'loadCacheOnly', true, 'verbose', verbose);
                resultTable = resultTable.updateInDatabase();
                loadCache = false;
                loadCacheOnly = true;
                timestampsByEntry = cell2mat(resultTable.cacheTimestampsByEntry);
                
                if checkCacheTimestamps && (~isempty(tableListCacheWarning) || ~isempty(tableListCacheInvalidate))
                    % warn about checking cache timestamps
                    debug('Warning: not checking cache timestamps for validity against relevant tables returned by getReferencesRelatedEntryNames (%s) or getEntryNamesChangesInvalidate (%s)\n', ...
                        strjoin(tableListCacheWarning, ','), strjoin(tableListCacheInvalidate, ','));
                end
                
                successFlag = resultTable.success;
                for iEntry = 1:resultTable.nEntries
                    if isempty(timestampsByEntry(iEntry).success)
                        maskAlreadyRun(iEntry) = false;
                        
                    else
                        maskAlreadyRun(iEntry) = true;
                        if ~successFlag(iEntry)
                            % success field found, but failed last time

                            % if it has a success field and it's marked as
                            % failed, consider it loaded. We'll rerunFailed
                            % below if requested
                            maskFailed(iEntry) = true;
                        else
                            maskFailed(iEntry) = false;
                        end
                    end
                end
                            
                debug('Valid cached success field found for %d of %d entries\n', nnz(maskAlreadyRun), length(maskAlreadyRun));
                debug('Previous run failed on %d of these %d cached entries\n', nnz(maskFailed), nnz(maskAlreadyRun));
            end

            % here we ask resultTable to check cache existence and timestamps
            % for all entries in the table. Timestamps are checked against
            if loadCache
                % load the table itself from cache and copy over additional field
                % values from the cache hit if present
                %if resultTable.hasCache()
                    % LoadOnDemandMappedTable will automatically add all rows in
                    % resultTable that are missing in the cached copy (i.e. rows
                    % in the mapped table that were added after the cache was generated).
                    % 
                    % So we don't need to worry about adding these missing rows

                    % IMPORTANT
                    % for now, all fields are cached to disk, so this step is unnecessary
                    % uncomment this if any fields are cached with the table
                    % because then loadFromCache will need to be called to retrieve
                    % these values. All fields currently are loaded by the .loadFields()
                    % call below.
                    % 
                    % resultTable = resultTable.loadFromCache();
                %end

                % check for modifications to related tables that should invalidate
                % the cached results. Entries with cached fields older than the 
                % most recent modification to the related entry names will be 
                % re run. The list of table entryNames to check is returned by
                % da.getEntryNamesChangesInvalidateCache()
                %
                % Also for the list of referenced entry names  returned by 
                % da.getReferencesRelatedEntryNames(), generate a warning 
                % if the cache is older than this value, but don't re run it

                % check the cache timestamps to determine
                % which entry x field cells are missing or out of date 
                debug('Checking cached field existence and success field\n');
                resultTable = resultTable.loadFields('fields', {'success'}, 'loadCacheOnly', true, 'verbose', verbose);
                fieldsToLoad = setdiff(resultTable.fieldsCacheable, 'success');
                % load the cache timestamps (and thereby determine whether
                % they exist) for all fields for successful entries
                resultTable = resultTable.loadFields('fields', fieldsToLoad, 'loadCacheTimestampsOnly', true, ...
                    'entryMask', resultTable.success, 'verbose', verbose);
                resultTable.updateInDatabase('filterOneToRelationships', false);

                timestampsByEntry = cell2mat(resultTable.getValues('cacheTimestampsByEntry'));
                
                if checkCacheTimestamps && ~isempty(tableListCacheWarning) || ~isempty(tableListCacheInvalidate)
                    % now we search for field values in fieldsAnalysis in the cache
                    debug('Checking cached field timestamps against dependencies\n');

                    resultTable = resultTable.updateInDatabase('filterOneToRelationships', false); %#ok<*PROP>
                    % get the most recent update for each table list
                    cacheWarningReference = db.getLastUpdated(tableListCacheWarning);
                    cacheInvalidateReference = db.getLastUpdated(tableListCacheInvalidate);

                    cacheWarningEntryCount = 0;
                    for iField = 1:length(fieldsAnalysis)
                        field = fieldsAnalysis{iField};
                        for iEntry = 1:resultTable.nEntries
                            timestamp = timestampsByEntry(iEntry).(field);
                            if isempty(timestamp) || timestamp < cacheWarningReference 
                                cacheWarningEntryCount = cacheWarningEntryCount + 1;
                            end
                            if isempty(timestamp) || timestamp < cacheInvalidateReference
                                maskCacheInvalidates(iEntry) = true;
                            end
                        end
                    end
                    if cacheWarningEntryCount > 0 
                        debug('Warning: This DatabaseAnalysis has % entries with cached field values older than\nthe modification time of tables this analysis references (see getReferencesRelatedEntryNames()).\nUse .deleteCache() or call with ''loadCache'', false to force a full re-run.\n', ...
                            cacheWarningEntryCount);
                    end
                    if any(maskCacheInvalidates)
                        debug('Warning: This DatabaseAnalysis has % entries with cached field values older than\nthe modification time of tables this analysis depends upon (see getEntryNamesChangesInvalidatesCache()).\nUse .deleteCache() or call with ''loadCache'', false to force a full re-run.\n', ...
                            nnz(maskCacheInvalidates));
                    end
                end
                
                % now we determine which entries have fully cached field values
                % and thus need not be rerun
                successFlag = resultTable.success;
                for iEntry = 1:resultTable.nEntries
                    if isempty(timestampsByEntry(iEntry).success) || ...
                       isnan(timestampsByEntry(iEntry).success)
                        % no success field found cached, not yet run
                        maskAlreadyRun(iEntry) = false;
                        
                    else
                        if ~successFlag(iEntry)
                            % success field found, but failed last time

                            % if it has a success field and it's marked as
                            % failed, consider it loaded. We'll rerunFailed
                            % below if requested
                            maskFailed(iEntry) = true;
                            maskAlreadyRun(iEntry) = true;
                    
                        else
                            % successful last time, check the existence of all fields
                            allLoaded = true;
                            for iField = 1:length(fieldsAnalysis)
                                field = fieldsAnalysis{iField};
                                if isempty(timestampsByEntry(iEntry).(field))
                                    allLoaded = false;
                                    break;
                                end
                            end

                            maskFailed(iEntry) = false;
                            maskAlreadyRun(iEntry) = allLoaded;
                        end
                    end    
                end
        
                debug('Valid cached field values found for %d of %d entries\n', nnz(maskAlreadyRun), length(maskAlreadyRun));
                debug('Previous run failed on %d of %d cached entries\n', nnz(maskFailed), nnz(maskAlreadyRun));
            end

            % reanalyze if any fields are missing, or if the cache is invalid
            maskToAnalyze = ~maskAlreadyRun | maskCacheInvalidates;
           
            if rerunFailed
                % rerun if failed last time
                maskToAnalyze = maskToAnalyze | maskFailed;
            end
           
            % pare down entries to analyze if manually specified
            if ~ismember(p.UsingDefaults, 'idx')
                maskManual = TensorUtils.vectorIndicesToMask(p.Results.idx, numel(maskToAnalyze));
                maskToAnalyze = maskToAnalyze & maskManual;
                debug('Manually sub-selecting %d entries to run due to idx parameter\n', numel(maskToAnalyze));
            end
         
            % NOTE: At this point you cannot assume that resultsTable and table (the mapped table)
            % are in the same order. They simply have the same number of rows mapped via
            % key field equivalence (1:1 relationship)

            % here we analyze entries that haven't been loaded from cache
            if ~loadCacheOnly
                nFailed = nnz(maskFailed);
                if nFailed > 0
                    if rerunFailed
                        debug('Rerunning on %d entries which failed last time\n', nFailed);
                    else
                        debug('Not rerunning on %d entries which failed last time\n', nFailed);
                    end
                end

                savedAutoApply = resultTable.autoApply;
                resultTable = resultTable.setAutoApply(false);
                
                nAnalyze = nnz(maskToAnalyze);
                if nAnalyze > 0
                    
                    % create a failure entry we can simply drop in when a
                    % failure occurs
                    failureEntry = struct();
                    for field = allFieldsAnalysis
                        dfd = resultTable.getFieldDescriptor(field{1});
                        failureEntry.(field{1}) = dfd.getEmptyValueElement();
                    end
                    
                    idxAnalyze = find(maskToAnalyze);

                    resultTableChanged = true;
                    
                    debug('Running analysis %s on %d of %d %s entries\n', name, ...
                        nAnalyze, table.nEntries, entryName);
                    
                    % load sources required ONLY for new analysis
                    da.database.loadSource(da.getRequiredSourcesForAnalysis());
                    
                    % actually run the analysis
                    for iAnalyze = 1:nAnalyze
                        iResult = idxAnalyze(iAnalyze);

                        % find the corresponding entry in the mapped table via the database
                        if maskToAnalyze(iResult)
                            % NOTE: ASSUMING THAT THE TABLES ARE ALIGNED AT
                            % THIS POINT!!!
                            %resultEntry = resultTable(iResult).apply();
                            %entry = resultEntry.getRelated(entryName);
                            entry = table.select(iResult);
                            
                            if entry.nEntries > 1
                                debug('WARNING: Multiple matches for analysis row, check uniqueness of keyField tuples in table %s. Choosing first.\n', entryName);
                                entry = entry.select(1);
                            elseif entry.nEntries == 0
                                % this likely indicates a bug in building / loading resultTable from cache
                                debug('WARNING: Could not find match for resultTable row in order to do analysis');
                                success = false;
                            end
                        end

                        description = entry.getKeyFieldValueDescriptors();
                        description = description{1};
                        progressStr = sprintf('[%5.1f %% - entry %d ]', (iAnalyze-1)/nAnalyze*100, iResult);
                        fprintf('\n');
                        [~, width] = getTerminalSize();
                        if isunix && ~ismac
                            cdash = char(hex2dec('2500'));
                        elseif ismac
                            cdash = char(hex2dec({'e2', '94', '80'}))';
                        else
                            cdash = '-';
                        end
                        line = [repmat(cdash, 1, width-1) '\n'];
                            
                        color = 'bright blue';
                        tcprintf(color, line);
                        tcprintf(color, '%s Running analysis on %s\n', progressStr, description);
                        tcprintf(color, line);
                        fprintf('\n');
                        
                        % for saveFigure to look at 
                        da.currentEntry = entry;

                        % clear debug's last caller info to get a fresh
                        % debug header
                        debug();
                        
                        % open a temporary file to use as a diary to capture all output
                        diary off;
                        diaryFile = tempname(); 
                        diary(diaryFile);
                        DatabaseAnalysis.setOutputLogStatus('file', diaryFile);

                        % clear the figure info for saveFigure to use
                        da.figureInfoCurrentEntry = [];

                        % try calling the runOnEntry callback
                        if catchErrors
                            try
                                resultStruct = da.runOnEntry(entry, fieldsAnalysis); 
                                exc = [];
                                success = true;
                                
                                if isempty(resultStruct)
                                    resultStruct = struct();
                                end
                                if ~isstruct(resultStruct)
                                    error('runOnEntry did not return a struct');
                                end
                            catch exc 
                                tcprintf('red', 'EXCEPTION: %s\n', exc.getReport);
                                success = false;
                                resultStruct = struct();
                            end
                        else
                            resultStruct = da.runOnEntry(entry, fieldsAnalysis); 
                            exc = [];
                            success = true;
                           
                            if isempty(resultStruct)
                                resultStruct = struct();
                            end
                            if ~isstruct(resultStruct)
                                error('runOnEntry did not return a struct');
                            end
                        end

                        % warn if not all fields requested were returned
                        % use the requested list fieldsAnalysis, a subset of dt.fieldsAnalysis
                        if success
                            missingFields = setdiff(fieldsAnalysis, fieldnames(resultStruct));
                            if ~isempty(missingFields)
                                debug('WARNING: analysis on this entry did not return fields: %s\n', ...
                                    strjoin(missingFields, ', '));
                            end
                            % warn if the analysis returned extraneous fields as a reminder to add them
                            % to .getFieldsAnalysis. Fields in dt.fieldsAnalysis but not fieldsAnalysis are okay
                            extraFields = setdiff(fieldnames(resultStruct), da.fieldsAnalysis);
                            if ~isempty(extraFields)
                                debug('WARNING: analysis on this entry returned extra fields not listed in .getFieldsAnalysis(): %s\n', ...
                                    strjoin(extraFields, ', '));
                            end
                        end

                        % load the output from the diary file
                        DatabaseAnalysis.setOutputLogStatus('file', '');
                        diary('off');
                        output = fileread(diaryFile);

                        % don't clutter with temp files
                        if exist(diaryFile, 'file')
                            delete(diaryFile);
                        end

                        
                        if success
                            tcprintf('bright green', 'Analysis ran successfully on this entry\n');
                            
                            % Copy only fieldsAnalysis that were returned.
                            % Fields in dt.fieldsAnalysis but not fieldsAnalysis are okay
                            [fieldsCopy, fieldsReturnedMask] = intersect(allFieldsAnalysis, fieldnames(resultStruct));
                        else
                            % Blank all fields (even if only some were
                            % requested), and set them in the table 
                            % This is to avoid conclusion or contamination
                            % with old results
                            resultStruct = failureEntry;
                            fieldsCopy = allFieldsAnalysis;
                            fieldsReturnedMask = true(length(allFieldsAnalysis), 1);
                            extraFields = {};
                        end
                        
                        if cacheFieldsIndividually
                            fieldsCopyIsDisplayable = fieldsAnalysisIsDisplayable(fieldsReturnedMask); 
                            for iField = 1:length(fieldsCopy)
                                field = fieldsCopy{iField};
                                % don't keep any values in the table, this way we don't run out of memory as the
                                % analysis drags on
                                % Displayable field values needed for report generation will be reloaded
                                % later on in this function
                                resultTable = resultTable.setFieldValue(iResult, field, resultStruct.(field), ...
                                    'saveCache', saveCache, 'storeInTable', storeInTable, 'verbose', verbose);
                            end
                        else
                            resultEntry = rmfield(resultStruct, extraFields); 
                        end

                        % set all of the additional field values
                        if cacheFieldsIndividually
                            saveCacheIndividual = true;
                        else
                            saveCacheIndividual = false;
                        end
                        
                        if saveCacheIndividual || storeInTable
                            resultTable = resultTable.setFieldValue(iResult, 'success', success, 'saveCache', saveCacheIndividual, 'storeInTable', storeInTable, 'verbose', verbose);
                            resultTable = resultTable.setFieldValue(iResult, 'output', output, 'saveCache', saveCacheIndividual, 'storeInTable', storeInTable, 'verbose', verbose);
                            resultTable = resultTable.setFieldValue(iResult, 'runTimestamp', da.timeRun, 'saveCache', saveCacheIndividual, 'storeInTable', storeInTable, 'verbose', verbose);
                            resultTable = resultTable.setFieldValue(iResult, 'exception', exc, 'saveCache', saveCacheIndividual, 'storeInTable', storeInTable, 'verbose', verbose);
                            resultTable = resultTable.setFieldValue(iResult, 'figureInfo', da.figureInfoCurrentEntry, 'saveCache', saveCacheIndividual, 'storeInTable', storeInTable, 'verbose', verbose);
                        end
                        
                        if ~cacheFieldsIndividually
                            resultEntry.success = success;
                            resultEntry.output = output;
                            resultEntry.runTimestamp = da.timeRun;
                            resultEntry.exception = exc;
                            resultEntry.figureInfo = da.figureInfoCurrentEntry;
                            resultTable = resultTable.updateEntry(iResult, resultEntry, 'saveCache', saveCache, 'storeInTable', false, 'verbose', verbose);
                        end
                        
                        if ~storeInTable
                            resultTable = resultTable.unloadFieldsForEntry(iResult);
                        end 

                        close all;
                    end
                end

                resultTable = resultTable.apply();
                resultTable = resultTable.setAutoApply(savedAutoApply);
                
                %fprintf('\n');
                debug('Finishing analysis run\n');
            end
            
            resultTable.updateInDatabase('filterOneToRelationships', false);

            % now fill in all of the info fields of this class with the full table data
            % these are mainly used by the DatabaseAnalysisHTMLWriter class
%             da.successByEntry = resultTable.getValues('success') > 0;                
%             da.exceptionByEntry = resultTable.getValues('exception');
%             da.figureInfoByEntry = resultTable.getValues('figureInfo');
%             da.logByEntry = resultTable.getValues('output');
            da.resultTable = resultTable;

            % mark loaded in database
            da.database.markSourceLoaded(da);
            da.hasRun = true;
            
            if ~isempty(p.Results.desc)
                da.runDescription = p.Results.desc;
            end

            if ~resultTableChanged && ~forceReport
                % if we haven't run new analysis, no need to build a report
                % so just use the timestamp from the most recent prior run
                dfd = da.resultTable.fieldDescriptorMap('runTimestamp');
                timeRunList = dfd.getAsDateNum(da.resultTable.getValues('runTimestamp'));
                if ~isempty(timeRunList)
                    da.timeRun = max(timeRunList);
                end
            elseif saveCache
                debug('Generating analysis report: loading displayable fields for all entries\n');
                % here we're writing the report
                % before we do this, we need to load the values of all displayable fields
                % and additional fields used in the report
                fieldsToLoad = intersect(da.resultTable.fieldsLoadOnDemand, da.resultTable.fieldsDisplayable);
                fieldsToLoad = union(fieldsToLoad, fieldsAdditional);
                da.resultTable = da.resultTable.loadFields('fields', fieldsToLoad, 'loadCacheOnly', true, 'verbose', verbose);
                da.resultTable.updateInDatabase('filterOneToRelationships', false);
                
                % make sure analysis path exists
                mkdirRecursive(da.pathAnalysis);
                chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, da.pathAnalysisRoot);
                chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, da.pathAnalysis);
                if exist(da.pathFigures, 'dir')
                    chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, da.pathFigures);
                    for i = 1:length(da.figureExtensions)
                        path = fullfile(da.pathFigures, da.figureExtensions{i});
                        if exist(path, 'dir')
                            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, path);
                        end
                    end
                end

                % sym link figures from prior runs to the current analysis folder
                da.linkOldFigures('saveCache', saveCache);
                % save the html report (which will copy resources folder over too)
                da.saveAsHtml();

                % link from analysisName.html to index.html for easy browsing
                da.linkHtmlAsIndex();

                % link this timestamped directory to current for easy browsing
                da.linkAsCurrent();
            end

            if saveCache && resultTableChanged
                % this isn't necessary right now as all values in the table are cached
                % separetely from the table. You must uncomment this if there are field values
                % saved with the table in the future (as well as the section above where 
                % the resultTable is loaded from cache)
                %
                % Cached field values have been cached as they were generated already
                % da.resultTable.cache('cacheValues', false);
            end
            
            debug('Call da.resultTable.loadFields().updateInDatabase(); to load analysis results\n');
            debug('Call da.viewAsHtml to view html report with figures and output\n');

            da.isRunning = false;
        end
        
        function saveFigure(da, figh, figName, figCaption)
            % use this to save figures while running the analysis
            if nargin < 4
                figCaption = '';
            end
            if nargin < 3 || isempty(figName)
                figName = get(figh, 'Name');
            end

            DatabaseAnalysis.pauseOutputLog();
            
            drawnow;
            if isempty(da.isRunning) || ~da.isRunning
                debug('Figure %s would be saved when run via DatabaseAnalysis.run()\n', figName);
                return;
            end

            entryTable = da.currentEntry;

            assert(entryTable.nEntries == 1);

            exts = da.figureExtensions;
            nExts = length(exts);
            success = false(nExts, 1);
            fileList = cell(nExts, 1);
            tcprintf('bright cyan', 'Saving figure %s as %s\n', figName, strjoin(exts, ', '));
            for i = 1:nExts
                ext = exts{i};
                fileName = da.getFigureName(entryTable, figName, ext);
                fileList{i} = resolveSymLink(GetFullPath(fileName));
                mkdirRecursive(fileparts(fileList{i}));
            end

            % let saveFigure do all of the work!
            saveFigure(fileList, figh);
            
            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, fileList);

            % log figure infomration
            figInfo.name = figName;
            figInfo.caption = figCaption;
            [figInfo.width figInfo.height] = getFigSize(figh);
            figInfo.extensions = exts;
            figInfo.fileLinkList = fileList;
            figInfo.fileList = fileList;
            figInfo.saveSuccessful = success;
            figInfo = orderfields(figInfo);

            % add to figure info cell
            if isempty(da.figureInfoCurrentEntry)
                da.figureInfoCurrentEntry = figInfo;
            else
                da.figureInfoCurrentEntry(end+1) = figInfo;
            end
            
            DatabaseAnalysis.resumeOutputLog();
        end

        function fileName = getFigureName(da, entryTable, figName, ext)
            % construct figure name that looks like:
            % {{analysisRoot}}/figures/ext/figName.{{keyField descriptors}}.ext
            
            if ischar(entryTable)
                descriptor = entryTable;
            else
                assert(entryTable.nEntries == 1);
                descriptors = entryTable.getKeyFieldValueDescriptors();
                descriptor = descriptors{1};
            end

            path = fullfile(da.pathFigures, ext);
            fileName = fullfile(path, sprintf('%s.%s.%s', figName, descriptor, ext));
            fileName = GetFullPath(fileName);
        end

        % create a symlink to index.html
        function linkHtmlAsIndex(da)
            da.checkHasRun();
            htmlFile = da.htmlFile;
            filePath = fileparts(htmlFile);
            indexLink = fullfile(filePath, 'index.html');
            if exist(indexLink, 'file')
                cmd = sprintf('rm "%s"', indexLink);
                [status, message] = unix(cmd);
                if status
                    fprintf('Error replacing index.html symlink:\n');
                    fprintf('%s\n', message);
                end
            end
            makeSymLink(htmlFile, indexLink);
            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, indexLink);
        end

        % symlink my analysis directory to "current" for ease of navigation
        function linkAsCurrent(da)
            da.checkHasRun();
            currentPath = GetFullPath(da.pathCurrent);
            thisPath = GetFullPath(da.pathAnalysis);
            if exist(currentPath, 'dir')
                cmd = sprintf('rm "%s"', currentPath);
                [status, message] = unix(cmd);
                if status
                    fprintf('Error replacing current symlink:\n');
                    fprintf('%s\n', message);
                end
            end
            makeSymLink(thisPath, currentPath);
            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, currentPath);
        end

        % symlink all figures loaded from cache that are not saved in the same
        % directory as the most recently generated figures
        function linkOldFigures(da, varargin)
            p = inputParser;
            p.addParameter('saveCache', true, @islogical);
            p.parse(varargin{:});
            saveCache = p.Results.saveCache;
            da.checkHasRun();

            if ~isunix && ~ismac 
                % TODO add support for windows nt junctions 
                return;
            end
            figurePath = da.pathFigures;
            nEntries = da.resultTable.nEntries;
            
            table = da.resultTable.table;
            emptyMask = arrayfun(@(x) isempty(x.figureInfo), table);
            
            if any(~emptyMask)
                prog = ProgressBar(nEntries, 'Creating symbolic links to figures saved in earlier runs');
                
                descriptors = da.resultTable.getKeyFieldValueDescriptors();

                for iEntry = 1:nEntries
                    if emptyMask(iEntry)
                        continue;
                    end
                    info = table(iEntry).figureInfo;
                    madeChanges = false;

                    prog.update(iEntry);
                    for iFigure = 1:length(info)
                        figInfo = info(iFigure);
                        for iExt = 1:length(figInfo.extensions)
                            try
                                mostRecentLink = resolveSymLink(figInfo.fileLinkList{iExt});
                                thisRunLocation = resolveSymLink(da.getFigureName(descriptors{iEntry}, figInfo.name, figInfo.extensions{iExt}));

                                if ~strcmp(mostRecentLink, thisRunLocation)
                                    % point the symlink at the original file, not at the most recent link
                                    % to avoid cascading symlinks
                                    actualFile = resolveSymLink(figInfo.fileList{iExt});
                                    success = makeSymLink(actualFile, thisRunLocation);
                                    if success
                                        % change the figure info link location, not the actual file path
                                        info(iFigure).fileLinkList{iExt} = thisRunLocation;
                                        madeChanges = true;

                                        % expose permissions on the symlink and the
                                        % original file, just in case
                                        chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, {actualFile, thisRunLocation});
                                    end
                                end
                            catch exc
                                debug('ERROR: linking old figure %s\n', figInfo.fileLinkList{iExt}); 
                            end
                        end
                    end

                    % update the figure info in the result table
                    if madeChanges
                        table(iEntry).figureInfo = info;
                    end
                end
            
                prog.finish();
                
                da.resultTable.table = table;
            end

        end

        function viewAsHtml(da)
            % da.checkHasRun(); % defer to current when not run yet
            fileName = da.htmlFile; 
            if ~exist(fileName, 'file')
                html = da.saveAsHtml();
            end
            HTMLWriter.openFileInBrowser(fileName);
        end
        
        function html = saveAsHtml(da)
            da.checkHasRun();
            fileName = da.htmlFile;
            debug('Saving HTML Report to %s\n', fileName);
            html = HTMLDatabaseAnalysisWriter(fileName);
            html.generate(da);
            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, html.fileName);
            chmod(MatdbSettingsStore.settings.permissionsAnalysisFiles, html.resourcesPathStore, 'recursive', true);
        end

        function disp(da)
            tcprintf('inline', '{bright blue}DatabaseAnalysis {none}: {bright white}%s{none} maps {bright white}%s\n', da.getName(), da.getMapsEntryName());
            tcprintf('inline', ['Parameters: ' da.getDescriptionParam() '\n\n']);
            builtin('disp', da);
        end
    end

    methods % Cacheable instantiations
        % return the cacheName to be used when instance 
        function name = getCacheName(obj)
            name = [obj.getName() '_analysis'];
        end

        function timestamp = getCacheValidAfterTimestamp(obj)
            % my data is valid until the last modification timestamp of the 
            if isempty(obj.database)
                % shouldn't happen when running normally, but could if cache functions
                % are called directly
                debug('Warning: Unable to determine whether analysis cache is valid because no .database found\n');
                
                % assume the cache is valid
                timestamp = -Inf;
            else
                % loop through these tables and find the latest modification time
                list = obj.getEntryNamesChangesInvalidateCache();
                
                % ask the database when the latest modification to these tables was
                timestamp = obj.database.getLastUpdated(list);
            end
        end
        
        function da = prepareForCache(da, varargin)
            p = inputParser;
            p.addParameter('snapshot', false, @islogical);  
            p.addParameter('snapshotName', '', @ischar);  
            p.KeepUnmatched = true;
            p.parse(varargin{:});
            
            if isempty(da.resultTable)
                error('Cannot cache DatabaseAnalysis before it has been initialized');
            end
        
%             if p.Results.snapshot
%                 % let the result table snapshot itself, then empty it
%                 da.resultTable.snapshot(p.Results.snapshotName);
%             else
%                 da.resultTable.cache();
%             end
%             da.resultTable = [];
        end
        
        function da = postLoadFromCache(da, param, timestamp, preLoadObj, varargin)
            p = inputParser;
            p.addParameter('snapshot', false, @islogical);  
            p.addParameter('snapshotName', '', @ischar);  
            p.KeepUnmatched = true;
            p.parse(varargin{:});
            
            if ~isempty(preLoadObj.database)
                da.setDatabase(preLoadObj.database);
            end
            
%             if p.Results.snapshot
%                 % let the result table snapshot itself, then empty it
%                 da.resultTable = da.resultTable.loadFromSnapshot(p.Results.snapshotName);
%             else
%                 % initialize if we need the result table to allow loading it from cache!
%                 if isempty(da.resultTable)
%                     da.initialize();
%                 end
%                 da.resultTable = da.resultTable.loadFromCache();
%             end
            
            if ~isempty(da.database)
                da.initialize();
            end
        end
    end

    methods % Dependent properties
        % path to folder of this run of this analysis
        function path = get.pathAnalysis(da)
            root = getFirstExisting(MatdbSettingsStore.settings.pathListAnalysis);
            name = da.getName();
            path = GetFullPath(fullfile(root, name, 'current'));
            if ~da.getIsRunning()
                return;
            else
                if isempty(da.timeRun) || isnan(da.timeRun)
                    timestr = 'current';
                else
                    timestr = datestr(da.timeRun, 'yyyy-mm-dd HH.MM.SS');
                end
                
                root = getFirstExisting(MatdbSettingsStore.settings.pathListAnalysis);
                name = da.getName();
                path = GetFullPath(fullfile(root, name, timestr));
            end
        end
        
        % path to parent folder of all runs of this analysis
        function path = get.pathAnalysisRoot(da)
            root = getFirstExisting(MatdbSettingsStore.settings.pathListAnalysis);
            name = da.getName();
            path = GetFullPath(fullfile(root, name));
        end  

        function path = get.pathCurrent(da)
            root = getFirstExisting(MatdbSettingsStore.settings.pathListAnalysis);
            name = da.getName();
            path = GetFullPath(fullfile(root, name, 'current'));
        end

        function path = get.pathFigures(da)
            path = GetFullPath(fullfile(da.pathAnalysis, 'figures'));
        end

        function fields = get.fieldsAnalysis(da)
            fields = da.getFieldsAnalysisAsValueMap();
        end

        function htmlFile = get.htmlFile(da)
            name = da.getName();
            path = da.pathAnalysis;
            fname = sprintf('%s.html', name);
            htmlFile = GetFullPath(fullfile(path,fname));
        end
    end

    methods % DataSource instantiations 
        % return a string describing this datasource
        function str = describe(da)
            str = da.getName();
        end

        % actually load this into the database, assume all dependencies have been loaded
        function loadInDatabase(da, database)
            da.database = database;
            da.initialize();
            
            % load success and run fields
            debug('%s: Loading specified analysis results fields\n', da.getName());
            fieldsToLoad = da.getFieldsToLoadOnDataSourceLoad();
            
            da.resultTable.loadFields(fieldsToLoad).updateInDatabase();
        end

        function useAsResultTable(da, resultTable)
            % utilize DataTable resultTable as .resultTable, and mark this analysis thereby loaded 
            % into the database. This allows other analyses / sources which require 
            % this analysis to be loaded in the database to proceed while acting on a 
            % specific results table as provided.
            %
            % TODO refactor this to avoid duplication in .run()
            
            % load all data sources
            db = da.database;
            if isempty(db)
                error('Please call .setDatabase(db)');
            end
            
            da.resultTable = resultTable;
            da.initialize();
            da.hasRun = true;
        end

        function deleteCache(da)
            if isempty(da.resultTable);
                r = DatabaseAnalysisResultsTable(da);
            else 
                r = da.resultTable;
            end
            r.deleteCache();
        end
    end
     
    methods % Caching utilities
        function fileList = getCacheFileListForReadForEntry(da, iEntry, varargin)
            if isempty(da.resultTable);
                r = DatabaseAnalysisResultsTable(da);
            else 
                r = da.resultTable;
            end
            fileList = r.getCacheFileListForReadForEntry(iEntry, varargin{:});
        end
        
        function fileList = getCacheFileForWriteForEntry(da, iEntry, varargin)
            if isempty(da.resultTable);
                r = DatabaseAnalysisResultsTable(da);
            else 
                r = da.resultTable;
            end
            fileList = r.getCacheFileForWriteForEntry(iEntry, varargin{:});
        end
    end
    
    methods(Static) % Diary file related statics
        function setOutputLogStatus(varargin)
            persistent currentDiaryFile;      
            p = inputParser;
            p.addParameter('file', '', @ischar);
            p.addParameter('paused', [], @islogical);
            p.parse(varargin{:});
            
            if ~isempty(p.Results.file)
                currentDiaryFile = p.Results.file;
            end
            
            if ~isempty(p.Results.paused)
                if p.Results.paused
                    diary off;
                else
                    if ~isempty(currentDiaryFile)
                        diary(currentDiaryFile);
                    end
                end
            end
        end
        
        function pauseOutputLog(da)
            DatabaseAnalysis.setOutputLogStatus('paused', true);
        end
        
        function resumeOutputLog(da)
            DatabaseAnalysis.setOutputLogStatus('paused', false);
        end
    end 
        
end
